import os
import json
import requests
from datetime import datetime
from prompt.get_system_prompt import get_system_prompt
from engine.memory_manager import MemoryManager

# -----------------------------
# æ¨¡å‹é…ç½®
# -----------------------------
# MODEL_NAME = "gemma3:1b"
MODEL_NAME = "qwen3:4b"
# MODEL_NAME = "huihui_ai/deepseek-r1-abliterated:8b"
API_URL = "http://localhost:11434/v1/chat/completions"

# åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
db_path = os.path.join(BASE_DIR, "game/data", "memory_db")
memory = MemoryManager(db_path=db_path, collection_name="story_memory")
# memory = MemoryManager(db_path="data/memory_db")

# -----------------------------
# è°ƒç”¨æ¨¡å‹å‡½æ•°
# -----------------------------
def call_model(messages, stream=False):
    """
    è°ƒç”¨æœ¬åœ°æ¨¡å‹ï¼Œæ”¯æŒæµå¼è¾“å‡ºã€‚
    stream=True æ—¶ä½¿ç”¨ç”Ÿæˆå™¨é€æ­¥è¿”å›ã€‚
    """
    payload = {
        "model": MODEL_NAME,
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 50000,
        "stream": stream
    }

    full_output = ""

    if stream:
        try:
            with requests.post(API_URL, json=payload, stream=True) as r:
                r.raise_for_status()
                for line in r.iter_lines():
                    if not line:
                        continue
                    decoded = line.decode("utf-8").strip()
                    if not decoded.startswith("data:"):
                        continue
                    data_str = decoded[len("data:"):].strip()
                    if data_str == "[DONE]":
                        break

                    try:
                        j = json.loads(data_str)
                        content = ""
                        choice = j.get("choices", [{}])[0]
                        if "delta" in choice:
                            content = choice["delta"].get("content") or ""
                        elif "message" in choice:
                            content = choice["message"].get("content") or ""

                        # Gemini é£æ ¼å…¼å®¹
                        if not content and "candidates" in j:
                            parts = j["candidates"][0].get("content", {}).get("parts", [])
                            content = "".join(p.get("text", "") for p in parts if "text" in p)

                        if content:
                            print(content, end="", flush=True)
                            full_output += content
                            yield content

                    except json.JSONDecodeError:
                        continue

        except Exception as e:
            print("[æµå¼è°ƒç”¨é”™è¯¯]", e)
        print("\n[æµç»“æŸ]")

    else:
        try:
            r = requests.post(API_URL, json=payload, timeout=30)
            r.raise_for_status()
            result = r.json()
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"].get("content", "")
            return ""
        except Exception as e:
            print("[éæµå¼è°ƒç”¨é”™è¯¯]", e)
            return ""


# -----------------------------
# ä¸»ç¨‹åº
# -----------------------------
def main():
    system_instructions = get_system_prompt("survival")
    # system_instructions = "ä½ æ˜¯ä¸€ä¸ªå…·å¤‡è®°å¿†åŠŸèƒ½çš„å¯¹è¯åŠ©æ‰‹ï¼Œèƒ½å¤Ÿå›å¿†ä¹‹å‰çš„æ•…äº‹ç‰‡æ®µã€‚"
    messages = [{"role": "system", "content": system_instructions}]

    print("=== å¸¦è®°å¿†çš„æ¨¡å‹è°ƒè¯•å·¥å…· ===")
    print("è¾“å…¥ 'exit' é€€å‡º\n")

    while True:
        user_input = input("ç”¨æˆ·: ").strip()
        if user_input.lower() in ["exit", "quit"]:
            break

        # ğŸ”¹ ä»è®°å¿†ä¸­æ£€ç´¢ç›¸å…³å†…å®¹
        related_context = memory.query_memory(user_input, top_k=3)
        if related_context:
            context_text = "\n".join(related_context)
            full_prompt = f"ä»¥ä¸‹æ˜¯ä½ ä¹‹å‰çš„è®°å¿†ï¼š\n{context_text}\n\nç°åœ¨ç”¨æˆ·è¯´ï¼š{user_input}"
        else:
            full_prompt = user_input

        # æ„é€ æ¶ˆæ¯åºåˆ—
        messages.append({"role": "user", "content": full_prompt})

        try:
            full_output = ""
            for chunk in call_model(messages, stream=True):
                full_output += chunk
            print("\n[æ¨¡å‹è¾“å‡ºå®Œæ¯•]")

            # ğŸ”¹ ä¿å­˜å¯¹è¯åˆ°å†å²ä¸è®°å¿†åº“
            messages.append({"role": "assistant", "content": full_output})
            memory.add_memory(f"ç”¨æˆ·ï¼š{user_input}\næ¨¡å‹ï¼š{full_output}")
            print("memory.add_memory = ", memory.add_memory(f"ç”¨æˆ·ï¼š{user_input}\næ¨¡å‹ï¼š{full_output}"))

        except Exception as e:
            print("[è°ƒç”¨æ¨¡å‹å‡ºé”™]", e)


if __name__ == "__main__":
    main()